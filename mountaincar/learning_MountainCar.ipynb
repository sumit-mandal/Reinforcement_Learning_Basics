{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d3a8a024-e941-46d3-a4e9-96fcebb9587d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ed9e1186-f392-454e-874e-7c59918d7166",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env.observation_space.high [0.6  0.07]\n",
      "env.observation_space.low [-1.2  -0.07]\n"
     ]
    }
   ],
   "source": [
    "env = gym.make(\"MountainCar-v0\")\n",
    "env.reset()\n",
    "\n",
    "done = False\n",
    "\n",
    "# we can query the enviornment to find out the possible ranges for each of these state\n",
    "print(\"env.observation_space.high\",env.observation_space.high)\n",
    "print(\"env.observation_space.low\",env.observation_space.low)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e2577fa8-dfbf-4ddc-b1a2-ca920b207407",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Discrete(3)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.action_space \n",
    "#Action 1 means push the car left action 2 means do nothing action 3 means push the car right"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f49eede-794e-4eef-932e-5ef2011ff793",
   "metadata": {},
   "source": [
    " \n",
    "` For the value at index 0, we can see the high value is 0.6, the low is -1.2, and then for the value at index 1, the high is 0.07, and the low is -0.07. Okay, so these are the ranges, but from one of the above observation states that we output: [-0.27508804 -0.00268013], we can see that these numbers can become quite granular. Can you imagine the size of a Q Table if we were going to have a value for every combination of these ranges out to 8 decimal places? That'd be huge! And, more importantly, it'd be useless. We don't need that much granularity. So, instead, what we want to do is conver these continuous values to discrete values. Basically, we want to bucket/group the ranges into something more manageable.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ffbc9819-bf27-46b3-b466-fd09ede8b27d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.09  0.007]\n"
     ]
    }
   ],
   "source": [
    "DISCRETE_OS_SIZE = [20]* len(env.observation_space.high) #observation size\n",
    "# size of len(env.observation_space.high) is 20 so it makes our DISCRETE_OS_SIZE = [20,20]\n",
    "discrete_os_win_size = (env.observation_space.high - env.observation_space.low)/DISCRETE_OS_SIZE\n",
    "\n",
    "print(discrete_os_win_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e08ba70-0df7-4036-ac68-d9ccae6d3e3f",
   "metadata": {},
   "source": [
    "`It will tells us how large each bucket is, basically how much to increment the range by for each bucket`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f3fa265-e8ee-4f92-bfaf-fc8e83f300dd",
   "metadata": {},
   "source": [
    "## Creating the Q-table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6a1220d2-3700-46c5-926f-ad4efc46c12d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q_table.shape (20, 20, 3)\n"
     ]
    }
   ],
   "source": [
    "q_table = np.random.uniform(low=-2,high=0,size=(DISCRETE_OS_SIZE + [env.action_space.n]))\n",
    "\n",
    "print(\"q_table.shape\",q_table.shape)\n",
    "\n",
    "#it makes q_table of the size (20,20,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0240e4d3-7f36-4ce9-9c8e-6a03fb47ebd1",
   "metadata": {},
   "source": [
    "`So, this is a 20x20x3 shape, which has initialized random Q values for us. The 20 x 20 bit is every combination of the bucket slices of all possible states. The x3 bit is for every possible action we could take.`\n",
    "\n",
    "`So these values are random, and the choice to be between -2 and 0 is also a variable. Each step is a -1 reward, and the flag is a 0 reward, so it seems to make sense to make the starting point of random Q values all negative.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "fdbca8c7-af16-415a-8eb5-b95336510c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "while not done:\n",
    "    action = 2 #By default we are pushing to the right\n",
    "    new_state,reward,done,info = env.step(action) #every time we step with an action we get a new_state from the environment\n",
    "    print(f\"reward{reward}\\n new_state{new_state}\\n\")\n",
    "    \n",
    "    # here state is it's poition and velocity\n",
    "    env.render()\n",
    "    \n",
    "env.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd65413b-5689-4d37-a6c3-a0131e58fdf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "! git add learning_MountainCar.ipynb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tf1.5]",
   "language": "python",
   "name": "conda-env-tf1.5-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
